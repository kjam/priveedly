{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c3a25-bf29-4236-b89e-f1926867c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import urlparse\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import html\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fca79d-1422-4b82-b973-4aefd64167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f91db7-9646-4975-bac6-42f91be92251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474b034-a67a-457d-9204-e798e2672469",
   "metadata": {},
   "source": [
    "## Priveedly: Training a Simple Content Recommender (Classifier) for Personal Use\n",
    "\n",
    "This notebook is originally for use with [Priveedly](https://blog.kjamistan.com/priveedly-your-private-and-personal-content-reader-and-recommender.html), a personal use content aggregator system available on [GitHub](https://github.com/kjam/priveedly).\n",
    "\n",
    "- There is a YouTube video to walk you through the notebook at a high level, in case it is helpful! \n",
    "- There are some links below to learn more about how to use scikit-learn.\n",
    "- I welcome feedback and contributions via GitHub!\n",
    "- Most importantly: HAVE FUN playing with ML concepts!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5a9fd-64eb-4038-a10e-24af5695aae1",
   "metadata": {},
   "source": [
    "# Getting text from Postgres into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64328592-1b29-4cca-a4e3-90dd4c3b0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data/cleaned.csv'):\n",
    "    print (\"SKIP TO LOADING CLEANED DF!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df266446-4771-4440-9c4b-8463703c509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(os.getenv('LOCAL_DB_CONNSTR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268bea0d-9996-4bf4-9ad7-040e15e2dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_df = pd.read_sql(\n",
    "    \"select title, url, description, site_name, interesting from sites_sitepost WHERE published::date >= '2023-01-01'\", \n",
    "    con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c072a4f-b809-44c6-b8e8-0ced8610b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds_df = pd.read_sql(\n",
    "    \"select feeds_feedentry.title as title, feeds_feedentry.url as url, feeds_feedentry.description as description, feeds_feed.title as site_name, interesting from feeds_feedentry JOIN feeds_feed ON feeds_feed.id = feed_id WHERE published::date >= '2023-01-01'\", \n",
    "    con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71050239-d0f4-49a6-bae0-e7e9fd943dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_sql(\n",
    "    \"select sites_redditpost.title as title, sites_redditpost.url as url, sites_redditpost.description as description, sites_subreddit.name as site_name, interesting from sites_redditpost JOIN sites_subreddit ON sites_redditpost.id = sites_subreddit.id WHERE published::date >= '2023-01-01'\", \n",
    "    con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee417e-18b6-4f3a-a31b-64544a81e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.concat([reddit_df, sites_df, feeds_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9729773-70ae-4951-b543-6a050f9d3615",
   "metadata": {},
   "source": [
    "# Evaluating target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92887ef8-85d8-4ba3-a446-a20e6072ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df.interesting = content_df.interesting.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77a6b1-6b09-4b04-8791-de63d7b8678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df.interesting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4276c-049e-4c58-bffc-8aaa2e94658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df.interesting.value_counts().iloc[0] / content_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965b795-cd98-4d8f-a57e-e44e641a37f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_df.interesting.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f5ad6-ac5c-49c4-be23-294a466f4e48",
   "metadata": {},
   "source": [
    "# Preparing the text data\n",
    "\n",
    "You'll need to take this code and put it into the priveedly rate_all.py script (see management_commands/rate_all.py) once you are running your pipeline in production. \n",
    "\n",
    "If you are using non-English languages, you probably want to play around and adjust this preparation to fit what works for you. I would love if you want to contribute any interesting additional notebooks to the repo! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72236a-7432-46a6-ad96-f23d12ef071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_url(url_str):\n",
    "    parsed_url = urlparse(url_str)\n",
    "    return parsed_url.netloc, ' '.join(parsed_url.path.split('/')).replace('-', ' '), parsed_url.query.replace('?', ' ').replace('=', ' ')\n",
    "\n",
    "def prepare_content(pandas_row):\n",
    "    netloc, path, query = tokenize_url(pandas_row.url)\n",
    "    return ' '.join([pandas_row.title, pandas_row.description, pandas_row.site_name])\n",
    "\n",
    "CLEAN_NUMBERS = re.compile('[0-9,\\\\.$\\\\%]+')\n",
    "CLEAN_NUMBERS_AND_ONE_LETTER = re.compile('([a-z]\\\\d+)|(\\\\d+[a-z])|(\\\\d+[a-z]\\\\d+)')\n",
    "CLEAN_REPEATED_PUNCTUATION = re.compile('[!\\\\-\\\\/:-@-`’–{-~\"“”\\\\[\\\\]]+')\n",
    "\n",
    "def remove_tags_and_lowercase(text): \n",
    "    # some parts from https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "    if BeautifulSoup(text, \"html.parser\").find():\n",
    "        try:\n",
    "            soup = BeautifulSoup(text)\n",
    "            text = soup.get_text()\n",
    "        except:\n",
    "            pass\n",
    "    cleantext = html.unescape(text).encode('unicode_escape').decode('unicode_escape')\n",
    "    # you can try this line or other similar things  if you want to be more deliberate about cleaning!\n",
    "    #cleantext = re.sub(CLEAN_NUMBERS_AND_ONE_LETTER, '', cleantext)\n",
    "    cleantext = re.sub(CLEAN_NUMBERS, '', cleantext)\n",
    "    cleantext = re.sub(CLEAN_REPEATED_PUNCTUATION, '', cleantext)\n",
    "    return cleantext.lower()\n",
    "\n",
    "removal = set(stopwords.words('english')).union(set(string.punctuation))\n",
    "\n",
    "def tokenize_content(text):\n",
    "    return [w for w in tokenize.word_tokenize(remove_tags_and_lowercase(text)) if w.lower() not in removal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c0d6c-dc05-4916-aec7-2b67d9588351",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df['full_text'] = content_df.apply(prepare_content, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2b39c-889d-4ed9-a322-a6b86855439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df['cleaned_text'] = content_df['full_text'].map(lambda x: ' '.join(tokenize_content(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561815b-9f3b-4408-ae84-5c97875ab78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = content_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e128c9-ec82-450e-8849-b49c7987b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[[\"full_text\", \"cleaned_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe81494-6edc-411e-a1a4-4fc931d2ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df.to_csv(\"data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11743eea-ad59-4420-8e9a-641766733b9a",
   "metadata": {},
   "source": [
    "### Now you can always load this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcdda5-9aa7-4e4e-aa17-7ce74fee0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.read_csv(\"data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc424f3-8b7d-4a35-80ab-51baa13f76d1",
   "metadata": {},
   "source": [
    "### Dealing with class imbalance\n",
    "\n",
    "My classes are really lopsided. Yours might be different! If you notice that yours are more even, you can use the orig_X_train as the X_train (and so forth!).\n",
    "\n",
    "To help with my lopsided classes, I will use [Imbalanced Learn](https://imbalanced-learn.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d510c49-ea58-4874-b8db-ba0768297d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed0d75-f9de-4c69-a0b3-77a92031a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_X_train, orig_X_test, orig_y_train, orig_y_test = train_test_split(content_df.cleaned_text, content_df.interesting, \n",
    "                                                    test_size=0.3, stratify=content_df.interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7326c30-44b2-4f0f-bd5a-d93d88cd2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(orig_y_train), Counter(orig_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db71c5-80b9-417e-b37e-6c579cf3a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = oversampler.fit_resample(content_df[[\"cleaned_text\"]].to_numpy(), content_df.interesting.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76509404-152d-46c1-b60f-2fe0b4371b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9045e-1490-4a8b-bd3e-7594943fb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res.flatten(), y_res, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ee16b-f4da-408f-93c7-3b629d815a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534aedb3-03ba-4ef7-85c3-a397a5013245",
   "metadata": {},
   "source": [
    "### Let's build some NLP pipelines with Scikit-learn!\n",
    "\n",
    "Scikit-learn is a great library for building machine learning models, especially with smaller personalized datasets, like this one! It has everything you need to get started and a great learning community and documentation.\n",
    "\n",
    "Want to learn more about scikit-learn and different machine learning models? Check out:\n",
    "\n",
    "- [Scikit-learn crash course](https://www.youtube.com/watch?v=0B5eIE_1vpU)\n",
    "- [Scikit-learn online learning course](https://inria.github.io/scikit-learn-mooc/)\n",
    "- [Calmcode](https://calmcode.io)\n",
    "- [probabl's YouTube Channel (some advanced topics)](https://www.youtube.com/@probabl_ai)\n",
    "\n",
    "Hat tip to [Vincent](https://github.com/koaning) for helping me assemble these resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd58cbb-3972-4506-b3e5-b2c5211f0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", SVC()),  # more complex, but maybe not worth it\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeab15f-a95f-4a86-aa7e-a9c1d506d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", ComplementNB()), # better at imbalance\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29b2b5-e681-42a6-a34d-7ec4befed5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", LogisticRegression()),  # simple, but maybe good enough\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a6091-1e7a-49d0-8bb0-360db18603e8",
   "metadata": {},
   "source": [
    "For looking up parameters to test, take a look at the following:\n",
    "\n",
    "- [TF-IDF Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- [SVC Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [Complement Naive Bayes Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html)\n",
    "- [LogisticRegression Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95d398-7f4c-47c2-a8d6-a3f271bae949",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_parameter_grid = {\n",
    "    \"vect__max_df\": (0.8, 0.9),\n",
    "    \"vect__min_df\": (0.01, 0.03),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #\"vect__norm\": (\"l1\", \"l2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814383d-aea9-438b-8795-d97c307cb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_parameter_grid = {\n",
    "    \"clf__C\": (1, 10), # inverse of regularization strength (smaller = more regularization)\n",
    "    \"clf__kernel\": ('rbf', 'sigmoid', 'poly') \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857aaca3-bdbf-4382-a723-c87fde3238cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_parameter_grid = {\n",
    "    \"clf__alpha\": np.logspace(-6, 6, 13), # Additive (Laplace/Lidstone) smoothing parameter \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce5e76-c849-4d51-8687-3aaa5d0f837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_parameter_grid = {\n",
    "    \"clf__C\": (1, 10), # inverse of regularization strength (smaller = more regularization)\n",
    "    \"clf__solver\": (\"lbfgs\", \"liblinear\", \"newton-cholesky\"), \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4859df-26c3-441d-bca4-3d2cc7bb659a",
   "metadata": {},
   "source": [
    "### Start by testing each model separately\n",
    "\n",
    "You can eventually productionize this with Weights and Biases, or just find the type of model that works best for your data and stick with that, updating only the training dataset over time. \n",
    "\n",
    "After you get your first model or two working, you likely also decide: oh I really only want to test SVC or I like having a fast LR model. Or even, I want to compare these simple models with a deep learning model or a local LLM.\n",
    "\n",
    "To test each one, change the lines below to reflect your changes:\n",
    "\n",
    "- use the parameter grid you set up above\n",
    "- change the model_name to something you will remember\n",
    "- change the estimator to the pipeline that you are evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ca6a9-a428-4ed1-9f24-7fc2cc8e49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = base_parameter_grid.copy()\n",
    "parameter_grid.update(logreg_parameter_grid) #CHANGE HERE: logreg_parameter_grid, cnb_parameter_grid, svc_parameter_grid\n",
    "model_name = \"LR\" # CHANGE HERE suggestion: LR, CNB, SVC\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=logreg_pipeline, # CHANGE HERE: logreg_pipeline, bayes_pipeline, svc_pipeline\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=20,\n",
    "    random_state=0,\n",
    "    n_jobs=4,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"Hyperparameters to be evaluated:\")\n",
    "pprint(parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a93f84-bd2c-4ee0-af08-b78a4418c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Done in {time() - t0:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe22603-c6d2-4ce6-903a-d07d5f28aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters combination found:\")\n",
    "best_parameters = random_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameter_grid.keys()):\n",
    "    print(f\"{param_name}: {best_parameters[param_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d892e1-e3e0-4f56-89ee-590f74b39360",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = random_search.score(X_test, y_test)\n",
    "print(f\"Accuracy of the best parameters using CV random search: {random_search.best_score_:.3f}\")\n",
    "print(f\"Accuracy on test set: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb3062-c050-4a3e-9188-fc489900cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f7dce-4564-45af-8607-9e4447222f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = {0: 'not interesting',\n",
    "                1: 'interesting'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50146191-cdb6-48ae-9af6-1ee33cde685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[human_labels[c] for c in random_search.classes_])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb04625-450f-40f0-9903-8d5412636c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_time = datetime.now().strftime(\"%Y%m%d_%H_%M\")\n",
    "with open(\"experiments/{}_{}.txt\".format(experiment_time, model_name), 'w') as documentation_file:\n",
    "    for param_name in sorted(parameter_grid.keys()):\n",
    "        documentation_file.write(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "    documentation_file.write(f\"Accuracy on the random search: {random_search.best_score_:.3f}\")\n",
    "    documentation_file.write(f\"Accuracy on test set: {test_accuracy:.3f}\")                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9465786-1310-4c06-ad81-db68a871e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline.set_params(**best_parameters) # CHANGE THIS: logreg_pipeline, bayes_pipeline, svc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7483cb0-871b-4212-934d-212ac7afb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(logreg_pipeline, \"experiments/models/{}_{}_pipeline.pkl\".format(experiment_time, model_name)) # CHANGE THIS: logreg_pipeline, bayes_pipeline, svc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6eff3d-2c9c-4745-a816-af60b65a695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = logreg_pipeline # CHANGE THIS: logreg_pipeline, bayes_pipeline, svc_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00371a-310d-4fe3-b647-e0c0dc178f80",
   "metadata": {},
   "source": [
    "If you ever want to load again, you can just:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08714b49-dd0b-472f-a306-cb5025c5d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load('experiments/models/20250121_19_46_SVC_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff4d4f-6141-4763-909e-ccf416836f33",
   "metadata": {},
   "source": [
    "### Investigating / interpreting your model\n",
    "\n",
    "So now you have an idea of the accuracy, but will it work for what you want to use it for? \n",
    "\n",
    "Let's say that it's really good at recognizing exactly your interests based on some silly keywords that you don't think will hold in practice. Or let's say you're also just curious about what keywords might be most interesting to you and want to have a look at the inner workings of your system. Either way, it's a good idea to investigate the model in order to qualitatively compare the models you've trained and determine which model you want to use.\n",
    "\n",
    "The following parts of the notebook can help you investigate and figure out how you think about the model decisions.\n",
    "\n",
    "#### Note: LIME Text Explainer doesn't appear to work for my data with SVC; but that might be different for you ! Let me know if it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447d5f4-c393-429b-90a7-c084a67cd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=[human_labels[c] for c in pipeline.classes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0ffa8-06e2-4523-ad86-335cc1376289",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = content_df.groupby(\"interesting\").sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b4111-1a40-4379-a968-d9e572b9f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fa799-82d4-4e07-a55c-a0ae249ffada",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pipeline.named_steps['vect']\n",
    "estimator = pipeline.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c5bc4-333f-4042-85b5-49efd602dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a fix for the SVC problem in LIME (see https://github.com/marcotcr/lime/issues/465)\n",
    "def classifier_fn(X):\n",
    "    vectorized_text_instance =  vectorizer.transform(X)\n",
    "    decision =                  estimator.decision_function(vectorized_text_instance)\n",
    "    reshaped_decision =         np.array(decision).reshape(-1, 1)\n",
    "    return reshaped_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c92fd-a7e8-41c1-bfc6-637e6ab47684",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in sample_df.cleaned_text: \n",
    "    try:\n",
    "        if hasattr(pipeline, 'predict_proba'):\n",
    "            exp = explainer.explain_instance(example, pipeline.predict_proba, labels=pipeline.classes_) \n",
    "        elif \"SVC\" in str(estimator): # this is hacky :(\n",
    "            exp = explainer.explain_instance(text_instance=example, classifier_fn=classifier_fn, labels=(0,))\n",
    "        exp.show_in_notebook()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('problem with this example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8267f-59c0-496c-b8cc-3d6f5c5c383d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "if hasattr(estimator, 'feature_log_prob_'): # bayesian\n",
    "    neg_class_prob_sorted = estimator.feature_log_prob_[0, :].argsort()[::-1]\n",
    "    pos_class_prob_sorted = estimator.feature_log_prob_[1, :].argsort()[::-1]\n",
    "elif hasattr(estimator, 'coef_'): # logreg\n",
    "    pos_class_prob_sorted = estimator.coef_[0, :].argsort()[::-1]\n",
    "    neg_class_prob_sorted = estimator.coef_[0, :].argsort()\n",
    "elif hasattr(estimator, 'kernel'): # svm\n",
    "    X = vectorizer.transform(X_train).toarray() # this is inefficient and it might run out of memory or timeout :(\n",
    "                                                # if this happens restart kernel and don't rerun  \n",
    "    perm_importance = permutation_importance(estimator, X, y_train)\n",
    "    pos_class_prob_sorted = perm_importance.importances_mean.argsort()\n",
    "    neg_class_prob_sorted = perm_importance.importances_mean.argsort()[::-1]\n",
    "\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(np.take(feature_names, neg_class_prob_sorted[:100]))\n",
    "print(np.take(feature_names, pos_class_prob_sorted[:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c814d-2212-4987-ae82-a5cf6d5a815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_rank(query):\n",
    "    i, = np.where(feature_names == query)\n",
    "    try:\n",
    "        pos_i = np.where(pos_class_prob_sorted == i)\n",
    "        neg_i = np.where(neg_class_prob_sorted == i)\n",
    "        if pos_i < neg_i:\n",
    "            print(\"ranked in positive score at position #{} out of {}\".format(pos_i[0][0], pos_class_prob_sorted.shape[0]))\n",
    "        else:\n",
    "            print(\"ranked in negative score at position #{} out of {}\".format(neg_i[0][0], neg_class_prob_sorted.shape[0]))\n",
    "    except ValueError:\n",
    "        print('token not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eea602-ed31-4031-a3cb-11c37961b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_word_rank(\"crypto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c69a0-60f4-43cd-8de6-cb6a4be4c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_word_rank(\"cryptography\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee4a34-3cb1-4de2-8ac4-0d0368ac6d41",
   "metadata": {},
   "source": [
    "### If this is the main one you want to use, store it as pipeline.pkl and upload it to your server :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d779a-04bf-4da5-a41e-e4f4b1dc66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, \"pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca277943-8f82-493b-801c-0a2bedc38d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
